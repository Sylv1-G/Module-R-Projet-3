# **Rapport du projet enjeux patrimoniaux**

# Auteurs : Ninon Delattre, Adèle Desaint, Sylvain Giraudo, Cyril Guillaumant, Louise Rovel # Date : 13/09/2024

# Introduction

## Présentation globale du projet 

Afin de gérer un massif forestier et d'écrire les documents d'aménagement, il
est nécessaire de s'intéresser au contexte de ce massif, dont les enjeux 
patrimoniaux qui y sont présents.
Ces informations (telles que les monuments historiques, les sites inscrits et 
classés, les aligements d'arbres...) se trouvent dans les documents d'urbanisme 
(PLU, PLUi, CC, PSMV) ainsi que dans les SUP (servitudes d'utilité 
publique) et les SCOT (Schémas de Cohérence Territoriale), et sont regroupées 
sur le géoportail de l'urbanisme. 

## Justification du besoin des données relatives aux enjeux patrimoniaux

Il est nécessaire de s'intéresser aux enjeux patrimoniaux d'un massif forestier 
car il en découle des contraintes voire des interdictions.
En effet, chaque prescription ou information de document d'urbanisme et chaque
servitude d'utilité publique est lié à un article de loi ou à un réglement des
codes forestier, de l'urbanisme, du patrimoine ou de l'environnement, qui en 
stipule les conséquences. 
Par exemple, une prescription ayant trait au patrimoine bâti ou paysager à 
protéger est liée à l'article L151-19 du code de l'urbanisme, qui stipule qu'il 
est obligatoire d'assurer leur préservation, leur conservation ou leur 
restauration. 

## Description des documents d'aménagements (et SUP)

![Documents d'urbanisme](1.png)
![Servitude d'Utilité Publique](2.png)

## Problématique 

Puisqu'il est nécessaire de s'intéresser aux enjeux patrimoniaux et que les 
informations qui y sont relatives sont regroupées sur le géoportail de 
l'urbanisme, il est possible et souhaitable d'automatiser la recherche de ces 
informations. 



# Matériel et Méthode

## Utilisation du géoportail de l'urbanisme et tri des données utiles
## Packages R : happign, tmap, sf, dplyr 
Un certain nombre de packages ont été utilisés pour réaliser notre projet:

happign, un package permettant de facilité l’accès au service web et API de l’IGN nous a permis de récupérer un grand nombre de données du Géoportail de l’urbanisme (GPU).

tmap, un package permettant d’éditer des données spatiales nous a quant à lui permis de visualiser nos résultats ainsi que de récupérer des emprises pour tester nos fonctions.

sf, qui est un package permettant de manipuler, importer et exporter des donnée spatiale

dplyr, permettant de manipuler des tableau de données dans R


## Autre methode : flux WFS du geoportail de l'urbanisme
## Méthode de réalisation de la fonction : plusieurs fonctions puis aggrégation
 
# Résultats

## Liste finale des données utiles dans les documents d'aménagement
## Les différentes fonctions réalisées selon la source de données
## Fonction finale et choix de l'utilisateur
## Les dyfonctionnement de la récupération par flux WFS
## Affichage des données récupérées

Les fonctions précédentes permettent d'extraire les données des différents documents d'urbanisme et des SUP. Elles ont été regroupées dans des tableaux contenant chacun une des informations suivantes : prescriptions, informations, générateurs et assiettes. Ces 4 tableaux ont été regroupés dans une liste NomDeLaListe. A présent, le but est d'exporter ces données sous la forme d'un géopackage afin de pouvoir les afficher sur un SIG.

Pour cela, une fonction export_list_to_gpkg a été crée. Elle prend en entrée la liste des 4 tableaux de données, une liste contenant les noms des fichiers de la future couche gpkg créée, ainsi qu'un chemin d'accès à cette future couche. 

```{r}
# Packages installation ----

library(librarian)
shelf(sf)

gpkg_path <- file.path("C:/Users/cyril/Downloads/FIF/ProjetRSIG/Module-R-Projet-3/Code/test.gpkg")

# Export a list of data frames to GPKG ----

layer_names <- c("prescriptions", "infos", "generateurs", "assiettes")

export_list_to_gpkg <- function(tes_all_gpu, layer_names, gpkg_path) {
  
  # Check that the number of layer names matches the number of data frames
  if (length(tes_all_gpu) != length(layer_names)) {
    stop("Le nombre de noms de couches doit correspondre au nombre de data frames.")
  }
  
  # Loop on each item in the list with layer names
  for (i in seq_along(tes_all_gpu)) {
    df <- tes_all_gpu[[i]]
    layer_name <- layer_names[i]
    st_write(df, gpkg_path, layer_name)
  }
}
```

Cette fonction va parcourir la liste contenant les 4 tableaux. Elle attribue un nom à chaque tableau (prescriptions, infos, générateurs ou assiettes) et convertit ses données en fichier gpkg. Chaque fichier ainsi créé sera ajouté à une unique couche gpkg.

Ainsi, lorsque les 4 tableaux auront été convertis, la couche gpkg créée contiendra 4 fichiers que l'on pourra afficher sur un logiciel de SIG.

# Discussion-Conclusion

## Autres données utiles récupérables par le geoportail, non relatives aux enjeux patrimoniaux (enjeux ecologiques => code de sylvain, mais aussi autres : ex richesse du sol, + possibilité de meilleur tri avec les sous codes)
## Possibilité de meilleur affichage des données récupérées
## Conclusion

# Bibliographie
# Module-R-Projet-3

Lien des standard des différents documents d'urbanisme :
https://cnig.gouv.fr/ressources-dematerialisation-documents-d-urbanisme-a2732.html

Lien code alphanumérique SUP : 
https://www.geoinformations.developpement-durable.gouv.fr/fichier/pdf/tableau_sup_codes_alpha-numerique_maj_20_06_24_2_cle5b12c4.pdf?arg=177836384&cle=d45a3272d7cdbd4f794a17e20e04a63590fc6a8b&file=pdf%2Ftableau_sup_codes_alpha-numerique_maj_20_06_24_2_cle5b12c4.pdf

Lien code SUP
https://www.geoinformations.developpement-durable.gouv.fr/fichier/pdf/tableau_alpha-numerique_des_supet_base_legale_maj_20_06_24_2_cle7dbc5e.pdf?arg=177836385&cle=0ef0d333b5d4e35418b5f3b71d2d3849a002c26f&file=pdf%2Ftableau_alpha-numerique_des_supet_base_legale_maj_20_06_24_2_cle7dbc5e.pdf
