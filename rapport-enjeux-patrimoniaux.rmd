# **Rapport du projet enjeux patrimoniaux**

# Auteurs : Ninon Delattre, Adèle Desaint, Sylvain Giraudo, Cyril Guillaumant, Louise Rovel 

# Date : 13/09/2024

# Introduction

## Présentation globale du projet

La gestion d'un massif forestier et l'écriture de documents d'aménagement nécessitent de s'intéresser aux enjeux environnants dont les enjeux patrimoniaux. Ces informations (telles que les monuments historiques, les sites inscrits et classés, les aligements d'arbres etc...) se trouvent dans des documents d'urbanisme (PLU, PLUi, CC, PSMV) ainsi que dans des SUP (Servitudes d'Utilité Publique) et des SCOT (Schémas de Cohérence Territoriale). Elles sont regroupées sur le géoportail de l'urbanisme.

## Justification du besoin des données relatives aux enjeux patrimoniaux

Il est nécessaire de s'intéresser aux enjeux patrimoniaux d'un massif forestier car il en découle des contraintes voire des interdictions. Chaque prescription ou information de document d'urbanisme et chaque SUP est liée à un article de loi ou à un réglement des codes forestier, de l'urbanisme, du patrimoine ou de l'environnement, qui en stipule les conséquences. Par exemple, une prescription ayant trait au patrimoine bâti ou paysager à protéger est liée à l'article L151-19 du code de l'urbanisme, qui stipule qu'il est obligatoire d'assurer leur préservation, leur conservation ou leur restauration.

## Description des documents d'aménagements (et SUP)

Le géoportail de l'urbanisme (GPU) permet d'acceder aux informations de différents documents d'urbanisme :

-   PLU (Plan Local d’Urbanisme) :\
    Le PLU est un document d'urbanisme à l'échelle communale qui définit les règles de construction et d'aménagement pour l'ensemble du territoire de la commune. Il détermine notamment l'affectation des sols, les zones constructibles, les hauteurs maximales des constructions, etc.

-   CC (Carte Communale) :\
    La Carte Communale est un document d'urbanisme simplifié qui délimite les zones constructibles et non constructibles sur le territoire d'une commune. Elle est utilisée principalement dans les petites communes qui ne disposent pas d'un PLU.

-   PSMV (Plan de Sauvegarde et de Mise en Valeur) :\
    Le PSMV est un document d'urbanisme spécifique aux secteurs sauvegardés, généralement des centres historiques, où il fixe des règles précises de préservation et de mise en valeur du patrimoine bâti. Il régit les travaux de construction, de rénovation, ou de démolition dans ces secteurs.

-   PLUi (Plan Local d’Urbanisme intercommunal) :\
    Le PLUi est un PLU qui s'applique non pas à une seule commune, mais à un ensemble de communes (intercommunalité). Il permet une planification cohérente et concertée à l'échelle de plusieurs communes.

-   SCOT (Schéma de Cohérence Territoriale) :\
    Le SCOT est un document de planification stratégique qui fixe les grandes orientations de l’aménagement du territoire à l'échelle de plusieurs communes ou d'une intercommunalité. Il couvre des domaines comme l'urbanisme, le logement, les transports, et l'environnement.

-   RNU (Règlement National d’Urbanisme) :\
    Le RNU est un ensemble de règles d'urbanisme qui s'appliquent dans les communes qui ne disposent pas de documents d'urbanisme locaux (comme un PLU). Ces règles définissent les conditions de construction et d'aménagement du territoire au niveau national.

-   SUP (Servitudes d’Utilité Publique) :\
    Les SUP sont des contraintes administratives imposées à certaines propriétés privées dans l'intérêt général. Elles sont liées à la présence d’infrastructures, de protections environnementales, ou de risques naturels, et limitent les droits d'usage et de construction sur les terrains concernés.

Ces différents documents jouent un rôle clé dans l'aménagement du territoire en France, en encadrant les projets d'urbanisme et en garantissant une cohérence entre les différents niveaux de planification (source : <https://www.legifrance.gouv.fr/codes/section_lc/LEGITEXT000006074075/LEGISCTA000031210062/#LEGISCTA000031212669>). Cependant, ils ne sont pas équivalents. Certains servent de substitution en l'absence de certains documents et d'autres prévalent sur le reste (<https://www.legifrance.gouv.fr/jorf/id/JORFTEXT000042007747/>).

![Documents d'urbanisme](1.png)

![Servitude d'Utilité Publique](2.png)

## Problématique

La nécessité de s'intéresser aux enjeux patrimoniaux pousse à automatiser l'importation des données regroupées sur le géoportail de l'urbanisme. Pour cela, il faudra d'abord identifier les documents d'urbanisme, SCOT ou SUP existant sur notre zone d'étude, puis récupérer les données utiles dans ces documents. 


# Matériel et Méthode

## Utilisation du géoportail de l'urbanisme : identification des documents d'urbanisme et tri des données utilisées

Afin de récupérer les données sur le géoportail de l'urbanisme, il est nécessaire
de comprendre ce qui identifie les documents, mais aussi comment les données y 
sont organisées. Cela permet de trier ces données en fonction de leur utilité dans l'écriture d'un document d'aménagement dont les informations relatives aux enjeux partimoniaux. 

Les documents d'urbanisme, les SCOT et les SUP sont identifiés par deux éléments :  
une partition et une localisation. 
La manière dont sont construites ces partitions, ainsi que la composition standard de chaque document, est disponible ici pour les documents d'urbanisme :  
https://cnig.gouv.fr/ressources-dematerialisation-documents-d-urbanisme-a2732.html.   
et ici pour les SUP :   
https://www.geoinformations.developpement-durable.gouv.fr/fichier/pdf/tableau_alpha-numerique_des_supet_base_legale_maj_20_06_24_2_cle7dbc5e.pdf?arg=177836385&cle=0ef0d333b5d4e35418b5f3b71d2d3849a002c26f&file=pdf%2Ftableau_alpha-numerique_des_supet_base_legale_maj_20_06_24_2_cle7dbc5e.pdf. 

Les partitions des documents d'urbanisme sont faciles à trouver
car elles ne prennent en compte que le type de document et le code INSEE des
communes, à l'exception des PLUi et des SUP. Les partitions des PLUi 
comprennent les codes des communautés de commune, tandis que les SUP, qui ne 
sont pas, par définition, des documents d'urbanisme, ont une partition 
complètement différente. 

Ainsi, afin de savoir s'il existe des documents d'urbanisme en un 
endroit donné, on récupère les codes INSEE des communes correspondantes. Ces codes INSEE
sont nécessaires pour savoir si la commune est soumise à un RNU. Si elle ne l'est
pas, c'est qu'il existe d'autres documents d'urbanisme. Le package happign permet de les récupérer.

Après avoir listé les documents d'urbanismes présents sur la zone d'étude, il est possible d'importer toutes les données utiles à partir de la localisation de la zone d'étude. L'importation des SUP et la décourverte de leur existance se déroule aussi à ce moments là.. 

Ensuite, les standards de ces documents servent à trier 
les données utiles aux forestiers, pour identifier les enjeux patrimoniaux par 
exemple, mais nous verrons par la suite que d'autres données intéressantes sont 
aussi disponibles. On prend donc une à une chacune des prescriptions et 
informations des documents d'urbanisme, et chacun des types de SUP, pour
identifier si elles correspondent à des enjeux patrimoniaux. Pour cela, il est
souvent nécessaire de se référer aux articles de loi ou réglements qu'elles
appliquent. 

## Packages R : happign, tmap, sf, dplyr 

Un certain nombre de packages ont été utilisés pour réaliser notre projet:  
**happign**, un package permettant de faciliter l’accès au service web et API de 
l’IGN. Ce package nous a permis de récupérer un grand nombre de données du 
géoportail de l’urbanisme (GPU) et de les intersecter facilement avec une 
zone d'étude, en particulier grâce à la fonction get_apicarto_gpu().  
**tmap**, un package permettant d’éditer des données spatiales nous a quant à 
lui permis de visualiser nos résultats ainsi que de récupérer des emprises pour 
tester nos fonctions.  
**sf**, qui est un package permettant de manipuler, importer et exporter des 
données spatiales.  
**dplyr**, permettant de manipuler facilement des tableau de données dans R.  

## Autre methode : flux WFS du geoportail de l'urbanisme

En dehors du package happign, il est également possible de récupérer directement
les flux WFS mis à disposition par le géoportail de l'urbanisme.  
Cette méthode a été explorée pour les SUP pour deux raisons.
La première raison est la complexité des partitions des SUP. En effet, 
contrairement aux partitions des documents d'urbanisme qui sont une combinaison 
de l'abrévation du document et du code INSEE des communes (par exemple, les 
partitions des PLU sont sous la forme DU_INSEE), les partitions des SUP 
prennent en compte la date de décision de la SUP et le type de SUP, deux 
informations qu'on ne peut obtenir sans connaitre la SUP au préalable. 
La deuxième raison est que, contrairement aux PLUi par exemple, il est impossible de 
récupérer les partitions des SUP grâce à la fonction happign::get_apicarto_gpu.  
La méthode utilisant directement les flux WFS s'appliquerait uniquement dans le 
cas où l'on ne souhaite travailler qu'avec des codes INSEE et non avec un vecteur
de surface correspondant à notre zone d'étude.  
Pour mettre en place cette méthode, il est nécessaire de se procurer le lien du 
service de téléchargement de flux WFS du géoportail de l'urbanisme :
https://data.geopf.fr/wfs/ows?SERVICE=WFS&VERSION=2.0.0&REQUEST=GetCapabilities. 
Ensuite, il faut récupérer les couches relatives aux SUP : celles des générateurs 
et celles de leurs assiettes, chacune déclinée en vecteurs surfaciques, linéaires
et ponctuels. Puis il faut manipuler les tableaux de données afin de faire 
l'intersection avec notre zone d'étude et trier les informations ayant trait aux
enjeux patrimoniaux.


## Méthode de réalisation de la fonction : plusieurs fonctions puis aggrégation

L'objectif de la fonction finale est de partir d'une zone d'étude et d'extraire les données associées aux enjeux patrimoniaux trouvées dans les documents d'urbanisme et les SUP. Cette fonction doit avoir plusieures propriétés. Elle doit permettre d'importer et de filtrer seulement les informations utiles à l'utilisateur. Elle doit pouvoir afficher ces informations sur une carte mais aussi les exporter sous forme de geopackage (.gpkg). C'est pourquoi la fonction se divise en plusieures étapes :

-   Tout d'abord, la zone d'étude, entrée sous format sf ou sfc, doit être tranformée dans un système de projection Lambert 93 et légèrement élargie grâce à un buffer. Ces deux étapes facilitent ensuite l'affichage et la lisibilité sur des cartes françaises. Le buffer permet également de récupérer des données sur une zone plus large.

-   Les données du géoportail de l'urbanisme se superposant à la zone d'étude peuvent ensuite être importées en quatre catégories : les prescriptions et les informations issues des documents d'urbanisme (PLU, PLUi, PSMV, CC), et les générateurs et les assiettes des SUP. Pour chacune de ces quatres catégories, un filtre est réalisé pour ne garder que les données liés aux enjeux patrimoniaux.

-   Ces quatres dataframe doivent ensuite être fusionnés dans une liste qui, après transformation du système de projection en Lambert 93, deviendra le resultat en sortie de la fonction.

Afin de rajouter des propriétés utiles à la fonction finale, un choix est laissé à l'utilisateur :

-   De réaliser un second filtre à la main après l'importation des données afin de diminuer la quantité d'informations extraites et de simplifier l'analyse des données.

-   D'afficher une carte brute des informations extraites avec le package tmap et de pouvoir explorer facilement les données.

-   D'exporter les données sous un format geopackage utilisable avec des logiciels SIG.

Cette fonction doit donc faire appel à de nombreuses petites fonctions permettant de réaliser tour à tour les tâches souhaitées.
 
# Résultats

## Liste finale des données utiles dans les documents d'aménagement

```{r, echo = FALSE }
code_prescription_patrimonial <- c("01", "07", "18", "31", "34", "35", "43",
                                   "46", "99")
libelle_prescription_patrimonial <- c(
  "Espace boisé classé",
  "Patrimoine bâti, paysager ou éléments de paysages à protéger",
  "Périmètre comportant des orientations d’aménagement et deprogrammation (OAP)",
  "Espaces remarquables du littoral",
  "Espaces, paysage et milieux caractéristiques du patrimoine naturel et culturel montagnard à préserver",
  "Terres nécessaires au maintien et au développement des activités agricoles, pastorales et forestières à préserver",
  "Réalisation d’espaces libres, plantations, aires de jeux et de loisir",
  "Constructibilité espace boisé antérieur au 20ème siècle",
  "Autre")

prescription_patrimonial <- data.frame(code_prescription_patrimonial,libelle_prescription_patrimonial)

code_info_patrimonial <- c("16", "25", "40", "99")
libelle_info_patrimonial <- c(
  "Site archéologique",
  "Périmètre de protection des espaces agricoles et naturels périurbain",
  "Périmètre d’un bien inscrit au patrimoine mondial ou Zone tampon d’un bien inscrit au patrimoine mondial",
  "Autre"
  )

info_patrimonial <- data.frame(code_info_patrimonial,libelle_info_patrimonial)

code_sup_patrimonial <- c("a10","ac1","ac4","ac2")

libelle_sup_patrimonial <- c(
  "Zones de protection naturelle, agricole et forestière du plateau de Saclay",
   "Servitudes relatives aux monuments historiques",
   "Sites patrimoniaux remarquables, zones de protection et de valorisation du patrimoine architectural, urbain et paysager",
   "Servitudes relatives aux sites inscrits et classés")


sup_patrimonial <- data.frame(code_sup_patrimonial,libelle_sup_patrimonial)



```
En utilisant les standards utilisés pour les documents d'urbanisme ainsi que les articles de loi qui s'y rattachent nous avons pu mettre en place la liste des enjeux patrimoniaux suivante :

```{r, echo = FALSE}
knitr::kable(prescription_patrimonial, caption = "liste des prescriptions retenues ayant trait aux enjeux patrimoniaux")
knitr::kable(info_patrimonial, caption = "liste des informations retenues ayant trait aux enjeux patrimoniaux")
knitr::kable(sup_patrimonial, caption = "liste des SUP retenues ayant trait aux enjeux patrimoniaux")
```
Il ne semble y avoir aucune donnée importante dans les SCOT. 

## Identification des documents d'urbanisme existant dans une zone 
## Les différentes fonctions d'importation utilisées selon la source de données

Une fonction d'importation est réalisée par source de données : prescriptions et
informations provenant des documents d'urbanisme, générateurs et assiettes des 
SUP, soit quatre fonctions au total. 

Ci-dessous l'exemple de la fonction permettant d'importer les prescriptions : 

```{r, echo = F}
library(librarian)
shelf(sf, httr,happign,dplyr,tmap)
library(tmap);tmap_mode("view")

code_prescription_general <- c("01", "07", "18", "19", "25", "31", "34", "35",
                               "43", "46", "99")
libelle_prescription_general <- c(
  "Espace boisé classé",
  "Patrimoine bâti, paysager ou éléments de paysages à protéger",
  "Périmètre comportant des orientations d’aménagement et deprogrammation 
  (OAP)",
  "Secteur protégé en raison de la richesse du sol et du sous-sol",
  "Eléments de continuité écologique et trame verte et bleue",
  "Espaces remarquables du littoral",
  "Espaces, paysage et milieux caractéristiques du patrimoine naturel et 
  culturel montagnard à préserver",
  "Terres nécessaires au maintien et au développement des activités agricoles, 
  pastorales et forestières à préserver",
  "Réalisation d’espaces libres, plantations, aires de jeux et de loisir",
  "Constructibilité espace boisé antérieur au 20ème siècle",
  "Autre")

# Codes et libelles des prescriptions relatives aux enjeux patrimoniaux
code_prescription_patrimonial <- c("01", "07", "18", "31", "34", "35", "43",
                                   "46", "99")
libelle_prescription_patrimonial <- c(
  "Espace boisé classé",
  "Patrimoine bâti, paysager ou éléments de paysages à protéger",
  "Périmètre comportant des orientations d’aménagement et deprogrammation 
  (OAP)",
  "Espaces remarquables du littoral",
  "Espaces, paysage et milieux caractéristiques du patrimoine naturel et 
  culturel montagnard à préserver",
  "Terres nécessaires au maintien et au développement des activités agricoles, 
  pastorales et forestières à préserver",
  "Réalisation d’espaces libres, plantations, aires de jeux et de loisir",
  "Constructibilité espace boisé antérieur au 20ème siècle",
  "Autre")

# Codes et libelles des prescriptions relatives aux enjeux ecologiques
code_prescription_ecologique <- c("01","18", "25", "34", "43", "99")
libelle_prescription_ecologique <- c(
  "Espace boisé classé",
  "Périmètre comportant des orientations d’aménagement et deprogrammation 
  (OAP)",
  "Eléments de continuité écologique et trame verte et bleue",
  "Espaces, paysage et milieux caractéristiques du patrimoine naturel et 
  culturel montagnard à préserver",
  "Réalisation d’espaces libres, plantations, aires de jeux et de loisir",
  "Autre")

# Codes et libelles des informations relatives a la gestion forestiere 
code_info_general <- c("03", "08", "16", "21", "22","25", "37", "40", "99")
libelle_info_general <- c(
  "Zone de préemption dans un espace naturel et sensible",
  "Périmètre forestier : interdiction ou réglementation des plantations (code 
  rural et de la pêche maritime), plantations à réaliser et semis d'essence 
  forestière",
  "Site archéologique",
  "Projet de plan de prévention des risques",
  "Protection des rives des plans d'eau en zone de montagne",
  "Périmètre de protection des espaces agricoles et naturels périurbain",
  "Bois ou forêts relevant du régime forestier",
  "Périmètre d’un bien inscrit au patrimoine mondial ou Zone tampon d’un bien 
  inscrit au patrimoine mondial",
  "Autre")

# Codes et libelles des informations relatives aux enjeux patrimoniaux
code_info_patrimonial <- c("16", "25", "40", "99")
libelle_info_patrimonial <- c(
  "Site archéologique",
  "Périmètre de protection des espaces agricoles et naturels périurbain",
  "Périmètre d’un bien inscrit au patrimoine mondial ou Zone tampon d’un bien 
  inscrit au patrimoine mondial",
  "Autre")

# Codes et libelles des informations relatives aux enjeux ecologiques 
code_info_ecologique <- c("03", "22", "99")
libelle_info_ecologique <- c(
  "Zone de préemption dans un espace naturel et sensible",
  "Protection des rives des plans d'eau en zone de montagne",
  "Autre")
                  
# Codes et libelles des SUP relatives a la gestion forestiere 
code_sup_general <- c("a1","a7","a8","el9","a4","as1","ac3","el10","a10",
                "ac1","ac4","ac2","pm1","el2","pm2","pm4","pm5",
                "pm6","pm7","pm8","pm9")
libelle_sup_general <- c(
  "Serviture de protection des bois et forêts relevant du régime forestier à 
  Mayotte",
  "Servitude relative aux forêts dites de protection",
  "Servitures résultant de la mise en défens des terrains et pâturages en 
  montagnes et dunes du Pas-de-Calais",
  "Servitudes de passage sur le littoral",
  "Servitudes de passage dans le lit ou sur les berges d'un cours d'eau",
  "Servitudes résultant de l'instauration de périmètres de protection autour 
  des captaux d'eaux et des sources minérales naturelles",
  "Réserves naturelles et périmètres de protection autour des réserves 
  naturelles",
  "Coeur de parc national",
  "Zones de protection naturelle, agricole et forestière du plateau de Saclay",
  "Servitudes relatives aux monuments historiques",
  "Sites patrimoniaux remarquables, zones de protection et de valorisation du 
  patrimoine architectural, urbain et paysager",
  "Servitudes relatives aux sites inscrits et classés",
  "Plans de prévention des risques naturels prévisibles (PPRNP) et plans de 
  prévention de risques miniers (PPRM) et documents valant PPRNP",
  "Servitude qui concerne la Loire et ses affluents",
  "Servitudes d'inondation pour la rétention des crues du Rhin",
  "Servitudes autour des installations classées pour la protection de 
  l’environnement et sur des sites pollués, de stockage de déchets ou 
  d’anciennes carrières",
  "Servitude relative aux zones de rétention d’eau et aux zones dites 
  'stratégiques pour la gestion de l’eau'",
  "Servitudes visant à ne pas aggraver les risques pour la sécurité publique en 
  présence d’un ouvrages hydraulique",
  "Servitudes autour des installations nucléaires de base",
  "Servitudes relatives aux ouvrages ou infrastructures permettant de prévenir 
  les inondations ou les submersions",
  "Servitudes relatives à la création, la continuité,la pérennité et 
  l’entretien des équipements de défense des forêts contre les incendies 
  (DFCI)",
  "Servitudes relatives aux zones de danger")

# Codes et libelles des SUP relatives aux enjeux patrimoniaux 
code_sup_patrimonial <- c("a10","ac1","ac4","ac2")

libelle_sup_patrimonial <- c(
   "Zones de protection naturelle, agricole et forestière du plateau de Saclay",
   "Servitudes relatives aux monuments historiques",
   "Sites patrimoniaux remarquables, zones de protection et de valorisation du 
   patrimoine architectural, urbain et paysager",
   "Servitudes relatives aux sites inscrits et classés")

# Codes et libelles des SUP relatives aux enjeux ecologiques 
code_sup_ecologique <- c("a8","a4","as1","ac3","el10","a10")
libelle_sup_ecologique <- c(
   "Servitures résultant de la mise en défens des terrains et pâturages en 
   montagnes et dunes du Pas-de-Calais",
   "Servitudes de passage dans le lit ou sur les berges d'un cours d'eau",
   "Servitudes résultant de l'instauration de périmètres de protection autour 
   des captaux d'eaux et des sources minérales naturelles",
   "Réserves naturelles et périmètres de protection autour des réserves 
   naturelles",
   "Coeur de parc national",
   "Zones de protection naturelle, agricole et forestière du plateau de Saclay")

# Selection des colonnes utiles dans les tableaux des generateurs et assiettes 
# de SUP
col_utiles_gen <- c("gid","suptype","partition","fichier","nomgen","typegen",
                   "nomsuplitt","geometry")
col_utiles_ass <- c("gid","suptype","partition","fichier","nomass","typeass",
                   "nomsuplitt","geometry")

# Uniformisation des noms de colonnes des tableaux des generateurs et assiettes 
# de SUP
noms_def <- c("gid","suptype","partition","fichier","nom","libelle",
              "nomsuplitt","geometry")

# Rassemblement de toutes les listes dans un seul repertoire
dico <- list(code_prescription_general = code_prescription_general,
             libelle_prescription_general = libelle_prescription_general,
             code_prescription_patrimonial = code_prescription_patrimonial,
             libelle_prescription_patrimonial = 
               libelle_prescription_patrimonial,
             code_prescription_ecologique = code_prescription_ecologique,
             libelle_prescription_ecologique = libelle_prescription_ecologique,
             code_info_general = code_info_general,
             libelle_info_general = libelle_info_general,
             code_info_patrimonial = code_info_patrimonial,
             libelle_info_patrimonial = libelle_info_patrimonial,
             code_info_ecologique = code_info_ecologique,
             libelle_info_ecologique = libelle_info_ecologique,
             code_sup_general = code_sup_general,
             libelle_sup_general = libelle_sup_general,
             code_sup_patrimonial = code_sup_patrimonial,
             libelle_sup_patrimonial = libelle_sup_patrimonial,
             code_sup_ecologique = code_sup_ecologique,
             libelle_sup_ecologique = libelle_sup_ecologique,
             col_utiles_ass =  col_utiles_ass,
             col_utiles_gen = col_utiles_gen,
             noms_def = noms_def)

```

```{r, eval=T, include=T}

Amiens <- get_apicarto_gpu("80021", ressource = "municipality")

# Recuperation des prescriptions sur le GPU
get.gpu.prescription <- function(x, dico){
  
  # Recuperation des surfaces, lignes et points
  prescription_surf <- get_apicarto_gpu(x,
                                        ressource = c("prescription-surf"))
  prescription_lin <- get_apicarto_gpu(x,
                                       ressource = c("prescription-lin"))
  prescription_pct <- get_apicarto_gpu(x,
                                       ressource = c("prescription-pct"))
  prescription_pct <- prescription_pct[ ,
                                        !(names(prescription_pct) %in% "angle")]

  # Creation d'un seul tableau avec les donnees surfaciques, lineaires et 
  # ponctuelles
  prescription <- rbind(prescription_surf, prescription_lin, prescription_pct)

  # Tri des prescriptions grace aux listes definies en debut de code 
  if (!is.null(prescription)){
    prescription <- 
      filter(prescription, typepsc %in% dico[["code_prescription_patrimonial"]])
    
  }
  return(prescription)
}

resultat = get.gpu.prescription(Amiens, dico)
```

```{r, echo = F}

knitr::kable(head(resultat[,"libelle"]), caption = "prescriptions retenues à Amiens")

```

## Choix de l'utilisateur

## Fonction finale

```{r}
final.function <- function(area,  # Geometrie
                           dico,  # Repertoire de listes
                           filter = "Patrimoine",  # Patrimoine,General ou 
                                                   # Ecologique
                           post_filter = FALSE,  # FALSE ou TRUE
                           working_dir = NULL,  # NULL ou repertoire de travail
                           buffer = 300,  # Entier en metres
                           display = FALSE,  # FALSE ou TRUE
                           export_gpkg = TRUE)  # TRUE ou FALSE
```

La fonction finale.fuction prend en entrée 8 arguments :  
- area qui correspond à la géométrie de la zone étudiée  
- dico qui contient les libellés de l'ensembles des prescriptions, informations et SUP en lien avec le sujet  
- filter qui vaut Patrimoine, General ou Ecologique afin de filtrer les données en sortie  
- post_filter qui vaut TRUE ou FALSE pour laisser ou non le choix à l'utilisateur d'un filtre plus personnalisé  
- working_dir qui correspond au dossier dans lequel le geopackage sera créé  
- une valeur de buffer  
- display et export_gpkg qui valent chacun TRUE ou FALSE pour lancer ou non les fonctions d'affichage des cartes sur R et de création du geopackage





## Les dyfonctionnement de la récupération par flux WFS

En utilisant les flux WFS du géoportail de l'urbanisme, une fonction 
permettant de récupérer les SUP d'une zone d'étude est écrite : 

```{r include=FALSE}
  # Ouverture des packages
  library(librarian)
  shelf(sf, httr,happign,dplyr,tmap)
  tmap_options(check.and.fix = TRUE)
  library(tmap);tmap_mode("view")
```

```{r, eval=T, include=T}
knitr::opts_chunk$set(echo = T)

get.sup <- function(x){

  # Recuperation des SUP
  wfs_url <- "https://data.geopf.fr/wfs/ows?SERVICE=WFS&VERSION=1.1.0&REQUEST=GetCapabilities"
  SUP_s <- st_read(wfs_url, layer = "wfs_sup:assiette_sup_s") 
  SUP_s <- st_transform(SUP_s, 2154)
  
  # Selection des SUP utiles 
  SUP_s <- SUP_s[
    SUP_s$suptype == "ac1"|   # monuments historiques
    SUP_s$suptype == "ac4"|   # patrimoine architectural
    SUP_s$suptype == "ac2",]   # sites inscrits et classes
  
  # Separation des geometries valides et invalides
  valid_SUP_s <- SUP_s[st_is_valid(SUP_s$the_geom) == T, ]
  invalid_SUP_s <- SUP_s[!st_is_valid(SUP_s$the_geom) == T,]

  # Recherche des SUP dans la commune consideree
  point <- get_apicarto_cadastre(x, type = "commune")
  point <- st_transform(point, 2154)

  SUP_s_point <- valid_SUP_s[st_intersection(valid_SUP_s$the_geom,point),]
  
  # Si la geometrie est invalide, on cherche le code INSEE dans les SUP
  SUP_commune <- grep(x, invalid_SUP_s$partition) 
  
  departement <- substring(x,1,2)
  SUP_departement <- grep("_'departement'_", invalid_SUP_s$partition)

  return(list(SUP_s_point, SUP_commune, SUP_departement))
  
}

resultat <- get.sup("80021") # Amiens
qtm(resultat[[1]])
```

Cela fonctionne malgré quelques problèmes rencontrés.  
Le premier est que la fonction recherche des intersections afin de savoir s'il 
y a des SUP dans la zone d'étude, ce qui présupose que les géometries soient 
valides. Or les géometries des assiettes des SUP ne sont pas toutes valides. Il 
faut donc séparer les SUP à géometries valides et invalides. Pour les géometries 
invalides, au lieu de rechercher une intersection, la fonction recherche le code 
INSEE de la commune dans les partitions des SUP, voire le code département. 
Cette recherche est donc laborieuse puisque si la fonction renvoie toutes les 
SUP du département, il faut ensuite les afficher toutes et chercher visuellement 
celles dans la zone d'étude.  
Le deuxième problème rend cette méthode invalide. En effet, les requêtes sur les
flux WFS sont paginées et limitées à 5000 éléments : la fonction ne renvoie donc
que les 5000 premières SUP de la liste, mais pas les autres.   
La méthode utilisant le service de téléchargement de flux WFS du géoportail de 
l'urbanisme ne sera donc pas utilisée.

## Affichage des données récupérées

```{r}
# Fonction d'affichage interactif ----

# Fonction pour afficher une carte interactive
affichage <- function(area, gpu_all, type = "Prescriptions"){
  
  # On peut afficher trois types de cartes 
  types <- c("Prescriptions", "Informations", "SUP")
  
  if (!type %in% types){
    stop ("Type must be 'Prescriptions', 'Informations' or 'SUP'")
  }
  
  # Utilisation de tmap en mode interactif
  tmap_mode("view")
  
  # Definition de l'affichage
  x <- 1  # Pour aller chercher le premier element de la liste gpu_all
  n <- 1  # Nombre iteration de la boucle for 
  if (type == "Informations"){
    x <- 2
  } else if (type == "SUP") {
    x <- 4
    n <- 2
  }
  
  # Creation de la carte interactive
  map <- tm_shape(area) +
    tm_borders(col = "black", lwd = 2) +
    tm_view(view.legend.position = c("right", "bottom"))
  
  
  for (i in 1:n){
    # Separation des types de geometries
    geometry_type <- st_geometry_type(gpu_all[[x]])
    
    polygones <- st_make_valid(gpu_all[[x]][geometry_type == "MULTIPOLYGON", ])
    lignes <- st_make_valid(gpu_all[[x]][geometry_type == "MULTILINESTRING", ])
    points <- st_make_valid(gpu_all[[x]][geometry_type == "MULTIPOINT", ])
    
    # Affichage des polygones
    if (nrow(polygones) > 0) {
      map <- map +
        tm_shape(polygones, group = "Polygones") +
        tm_fill(col = "libelle",
                alpha = ifelse(x == 4, 0.1, 0.9),
                palette = "Spectral",
                title = ifelse(x == 4, 
                               "Assiette SUP", 
                               paste(type, "surfaciques")), 
                legend.show = TRUE) +  
        tm_borders()
    }
    
    # Affichage des lignes
    if (nrow(lignes) > 0) {
      map <- map +
        tm_shape(lignes, group = "Lignes") +
        tm_lines(col = "libelle", 
                 palette = "Accent", 
                 title.col = ifelse(x == 4, 
                                    "Assiette SUP", 
                                    paste(type, "lineaires")),
                 legend.show = TRUE)
    }
    
    # Affichage des points
    if (nrow(points) > 0) {
      map <- map +
        tm_shape(points, group = "points") +
        tm_symbols(col = "libelle",
                   palette = "Paired",
                   shape = 21,
                   size = 0.2,
                   title.col = paste(type, "ponctuelles"))
    }
    x <- x - 1  # Pour passer de l'affichage des assiettes a l'affichage des 
                # generateurs
  }
  print(map)
  
}

# Affichage des trois types de cartes 
affichage.interactif <- function (area, gpu_all) {
  
  cat("\nLes trois cartes vont s'afficher au fur et à mesure.\n")
  
  for (type in c("Prescriptions", "Informations", "SUP")){
    
    cat(paste("\nAffichage des", type))
    
    affichage(area, gpu_all, type)
  }
}
```

Les fonctions précédentes permettent d'extraire les données des différents documents d'urbanisme et des SUP. Elles ont été regroupées dans des tableaux contenant chacun une des informations suivantes : prescriptions, informations, générateurs et assiettes. Ces 4 tableaux ont été regroupés dans une liste NomDeLaListe. A présent, le but est d'exporter ces données sous la forme d'un géopackage afin de pouvoir les afficher sur un SIG.

Pour cela, une fonction export.list.to.gpkg a été crée. Elle prend en entrée la liste des 4 tableaux de données ainsi qu'un chemin d'accès à cette future couche. 

```{r}
# Exporte une liste de data frame sous forme de geopackage 

export.list.to.gpkg <- function(gpu_all, gpkg_path) {
  
  layer_names <- c("prescriptions", 
                   "infos", 
                   "generateur", 
                   "assiette")
  
  # Chaque obejt de la liste est nommé puis exporté sous forme de fichier dans 
  # un unique geopackage
  for (i in seq_along(gpu_all)) {
    df <- gpu_all[[i]]
    layer_name <- layer_names[i]
    st_write(df, gpkg_path, layer_name, append = T)
  }
}

```

Cette fonction va parcourir la liste contenant les 4 tableaux. Elle attribue un nom à chaque tableau (prescriptions, infos, générateurs ou assiettes) et convertit ses données en fichier gpkg. Chaque fichier ainsi créé sera ajouté à une unique couche gpkg.

Ainsi, lorsque les 4 tableaux auront été convertis, la couche gpkg créée contiendra 4 fichiers que l'on pourra afficher sur un logiciel de SIG.

# Discussion-Conclusion

## Autres données utiles récupérables via le GPU, non relatives aux enjeux patrimoniaux

Dans un premier temps, seules les données relatives aux enjeux patrimoniaux ont 
été sélectionnées au sein des documents d'urbanisme et des SUP. Seulement, il 
existe de nombreuses données dans ces documents qui ne concernent pas les 
enjeux patrimoniaux mais qui peuvent tout de même être intéressantes pour la 
gestion forestière et la rédaction des documents d'aménagement.  

Ainsi, les données extraites des documents d'urbanisme et des SUP ont été triées 
selon leur catégorie : général, patrimonial et écologique. Ce tri a été effectué 
toujours de la manière la plus précise possible, à l'aide des lois et 
règlements rattachés aux prescriptions, informations et SUP. Ensuite, une 
variable **filter** a été ajoutée à la fonction finale, permettant de choisir
quelle catégorie de donnée l'on souhaite récupérer.  

Néanmoins, il demeure possible que certains éléments se retrouvent dans une 
catégorie inadaptée, en particulier parce que certaines prescriptions sont 
très larges. En effet, la dénomination des éléments (prescriptions, 
informations, SUP) se retrouvant dans la variable filter repose sur un 
code indiquant la nature de ces éléments. Or, il existe également des 
sous-codes plus précis. Cependant, ce sous-code n'a pas été pris en compte 
lors de la création de la variable filter. Par exemple, les prescriptions 99
s'intitulent : "Autre : zones naturelles, agricoles ou forestières". On y trouve
les prescriptions 99-02 intitulés "Autre : zones naturelles, agricoles ou 
forestières", pouvant être importantes pour la gestion forestière, mais aussi 
les prescriptions 99-03 intitulés "Autre : mixité sociale et fonctionnelle en 
zones urbaines ou à urbaniser", ne concernant aucunement la forêt. L'utilisateur
doit donc lui-même faire un dernier tri.


## Possibilité de meilleur affichage des données récupérées

# Conclusion

# Bibliographie
# Module-R-Projet-3

Lien des standard des différents documents d'urbanisme :
https://cnig.gouv.fr/ressources-dematerialisation-documents-d-urbanisme-a2732.html

Lien code alphanumérique SUP : 
https://www.geoinformations.developpement-durable.gouv.fr/fichier/pdf/tableau_sup_codes_alpha-numerique_maj_20_06_24_2_cle5b12c4.pdf?arg=177836384&cle=d45a3272d7cdbd4f794a17e20e04a63590fc6a8b&file=pdf%2Ftableau_sup_codes_alpha-numerique_maj_20_06_24_2_cle5b12c4.pdf

Lien code SUP
https://www.geoinformations.developpement-durable.gouv.fr/fichier/pdf/tableau_alpha-numerique_des_supet_base_legale_maj_20_06_24_2_cle7dbc5e.pdf?arg=177836385&cle=0ef0d333b5d4e35418b5f3b71d2d3849a002c26f&file=pdf%2Ftableau_alpha-numerique_des_supet_base_legale_maj_20_06_24_2_cle7dbc5e.pdf
